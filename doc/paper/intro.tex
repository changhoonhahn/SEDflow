\section{Introduction} \label{sec:intro} 
Over the past few decades, observations from large galaxy surveys such as the
Sloan Digital Sky Survey~\citep[SDSS;][]{york2000}, DEEP2~\citep{davis2003},
COSMOS and zCOSMOS~\citep{scoville2007, lilly2007}, and GAMA~\citep{baldry2018}
have transformed our understanding of how galaxies form and evolve. 
The building blocks of our physical insight into galaxies are their 
physical properties measured from these observations: \emph{e.g.} stellar mass ($M_*$), star formation rate
(SFR), metallicity ($Z$), and age ($t_{\rm age}$).
The primary way for measuring these galaxy properties is by analyzing their
spectral energy distribution (SED).

% primer on SED modeling 
All of the physical processes in a galaxy leave an imprint on its SED.
%\emph{e.g.} its star formation history, chemical enrichment history, dust content. 
For instance, the SED over the ultraviolet to infrared wavelengths is
primarily composed of light from the galaxy's stellar populations and, thus,
encodes the galaxy's star formation and chemical enrichment histories.  
How some of this stellar light is reprocessed reflects the gas and dust content
of the galaxy's interstellar medium.
The goal of SED modeling is to extract the detailed physical properties of
galaxies that are encoded in observed SEDs. 
There are three key components to SED modeling: the observations, a physical SED
model, and a statistical inference framework for deriving physical properties 
from comparisons between the observations and models.

% brief primer on SPS 
Current SED models are based on stellar population synthesis (SPS).
Broadly speaking, they model the SED of a galaxy as a compsite stellar
population constructed from isocrhones, stellar spectra, an initial mass
function (IMF), a star formation and chemical evolution history, and dust
attenuation~\citep[\emph{e.g.}][]{bruzual2003, maraston2005, conroy2009}.
Some models also include dust and nebular emissions as well as emissions from
active galactic nuclei~\citep[\emph{e.g.}][]{johnson2021}.
For a comprehensive review on SPS and SED modeling, we refer readers to
\cite{walcher2011} and \cite{conroy2013}. 

% parameter inference for SED modeling
In this work, we focus on the third component of SED modeling: the statistical
framework for comparing the physical SED models to observations and inferring
galaxy properties. 
State-of-the-art SED modeling use a Bayesian inference framework.
This approach has a number of key advantages over maximum-likelihood 
approaches~\citep[\emph{e.g.}][]{cidfernandes2005, tojeiro2007, koleva2008} 
that were often used in the past.
In Bayesian inference, the goal is to estimate $p(\theta\given\bfi{x})$, the
probability distribution of parameters $\theta$, in our case galaxy
properties, given observation $\bfi{x}$. 
Inferring $p(\theta\given\bfi{x})$ provides an accurate estimate of parameter 
uncertainties and any degerancies among them that can then be propagated for
more accurate statistical analyses. 
The Bayesian framework also enables marginalization over nuisance parameters,
which is necessary to model the effects of observational systematics
(\emph{e.g.} flux calibration).
In principle, Bayesian inference also allows us to exploit informative priors
based on previous observations to derive more precise constraints on galaxy
properties. 

In practice, current Bayesian methods use Markov Chain Monte Carlo (MCMC) 
sampling techniques to explore and estimate the posterior~\citep{acquaviva2011,
chevallard2016, leja2017, carnall2018}. 
MCMC sampling enables more accurate posterior estimation and addresses the
curse of dimensionality that restricts grid-based techniques often used in the
past~\citep{kauffmann2003a, burgarella2005, salim2007, dacunha2008}.
Grid-based techniques require SED models to be pre-computed over a grid in
parameter space.
Hence, as the dimensionality of model parameters increases for more
sophisticated models, they require exponentially large number of model
evaluations.
Meanwhile for MCMC, the number of evaluations scales roughly linearly with the
number of parameters.  
In \cite{johnson2021}, for instance, they use MCMC to sample a 16-dimensional
parameter space. 

Despite their advantages, current Bayesian SED modeling methods are \emph{not
scalable} as upcoming galaxy surveys will observe an unprecedented number of
galaxies.
The Dark Energy Spectroscopic Survey~\citep[DESI;][]{desicollaboration2016},
the Prime Focus Spectrograph~\citep[PFS;][]{takada2014},
Rubin observatory~\citep{ivezic2019}, and Roman Space
Telescope~\citep{spergel2015} will all observe \emph{millions} of galaxy SEDs. 
Meanwhile, current SED modeling takes 10-100 CPU hours per
galaxy~\citep[\emph{e.g.}][]{carnall2019a, tacchella2021}.
With current methods, inferring galaxy properties from rigorous Bayesian SED
modeling for upcoming surveys  would require \emph{billions} of CPU hours. 
%For example, in \cite{}, analyzing just ${\sim}4000$ galaxies in the LEGA-C ESO Public Spectroscopic Survey~\cite{} using {\sc Bagpipes} required 3.5 million CPU hours.

The computational challenge is further exacerbated by additional factors. 
First, more accurate and sophisticated SED models require additional
parameters. 
For instance, modeling additional physical processes such as nebular emission
requires additional parameters. 
Accurately incorporating observational effects also requires extra parameters.
As the dimensionality expands, conventional sampling techniques are less
efficient. 
Second, it has recently come to light that the prior, used to evaluate the
posterior, can significantly impact the inferred galaxy
properties~\citep{carnall2017, leja2017, hahn2022}. 
This is a consequence of the fact that galaxy properties are not input SED
model parameters but rather derived quantities (see Appendix of
\citealt{hahn2022}).
Hence, deriving robust galaxy properties requires validating the properties
using different priors and investigating their impact. 
For MCMC-based methods, posteriors would need to be re-evaluated from scratch
for each prior.
Lastly, current SED modeling make strong theoretical assuptions. 
They make explicit choices for stellar spectral library and initial mass
function, even though there is no consensus. 
Relaxing these assumptions would involve flexibly parameterizing the
uncertainties and variations as additional parameters in SED
models~\citep{conroy2009, conroy2010} or deriving galaxy properties for
multiple sets of assumptions. 
Both options increase the computational costs of current SED modeling.  

Rigorous Bayesian inference, however, does not require MCMC sampling. 
Simulation-based inference (SBI; also known as ``likelihood-free inference'')
is a rapidly developing class of inference methods that offers better
alternatives for many applications~\citep[see][and reference
therein]{cranmer2020}.
Many SBI methods leverage the latest developments in statistics and Machine
Learning for more efficient posterior estimation~\citep{papamakarios2017,
alsing2019a, hahn2019c, dax2021, huppenkothen2021, zhang2021}. 
One such SBI technique optimal for scalable Bayesian inference is Amortized
Neural Posterior Estimation (ANPE). 

ANPE utilizes a density estimation approach to SBI. 
Instead of using MCMC to sample the posterior, $p(\theta \given \bfi{x}_i)$, 
of a single galaxy, $i$, ANPE uses neural density estimators (NDE) and training
data to estimate $p(\theta\given\bfi{x})$  over the full space of observables
$\bfi{x}$.
NDEs are density models parameterized by neural networks that estimate
density/probability distributions. 
The training data are $\{(\theta_i, \bfi{x}'_i)\}$ pairs.
In our application, $\theta$ is the SED model parameters, sampled from a 
prior, and $\bfi{x}'_i$ are synthetic observables, such as photometry, forward
modeled using the SED model. 
Once the NDE is trained, generating the posterior requires no additional model
evaluations and only requires plugging in the observation $\bfi{x}_i$.
%--- this takes ${\sim}1$ second. 

ANPE addresses one of the major drawbacks of MCMC: SED model evaluations used
for one galaxy cannot be used for another.
This is why MCMC sampling has to be performed on every galaxy. 
In ANPE, models evaluations are only used to construct the training data of the
NDE. 
Although the training set typically requires more evaluations than for a single
MCMC posterior, no additional evaluations are necessary after training. 
Hence, the computational cost is \emph{amoritzed} and only a minuscule
fraction of the cost of performing MCMC to analyze a large set of observations.
ANPE has recently been applied to a wide range of applications in physics and
astronomy with remarkable success~\citep{stein2020, wong2020, dax2021,
zhang2021}.

In this work, we present \sedflow, a method that applies ANPE to Bayesian
galaxy SED modeling using the recent \cite{hahn2022} SED model. 
We demonstrate that we can derive accurate posteriors with \sedflow~and make
Bayesian SED modeling fully scalable for the millions of galaxies that will be
observed by upcoming surveys.
As further demonstration, we apply ANPE to analyze optical photometry of
${\sim}33,000$ galaxies in the NASA-Sloan
Atlas~(NSA\footnote{\url{http://www.nsatlas.org/}}). 
We begin in Section~\ref{sec:sbi} by describing SBI using ANPE.
We then describe the NSA observations in Section~\ref{sec:obs}. 
Afterwards, we present how we design and train \sedflow~in
Section~\ref{sec:sedflow}. 
We validate the accuracy of the posteriors from \sedflow~in
Section~\ref{sec:results} and discuss the impliciation of our results and
future steps in Section~\ref{sec:discuss}. 
