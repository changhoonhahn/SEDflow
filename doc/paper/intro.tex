\section{Introduction} \label{sec:intro} 
Over the past few decades, observations from large galaxy surveys such as the
Sloan Digital Sky Survey~\citep[SDSS;][]{york2000}, DEEP2~\citep{davis2003},
COSMOS and zCOSMOS~\citep{scoville2007, lilly2007}, and GAMA~\citep{baldry2018}
have transformed our understanding of how galaxies form and evolve. 
The building blocks of our physical insight into galaxies are their 
physical properties, \emph{e.g.} stellar mass ($M_*$), star formation rate
(SFR), and metallicity ($Z$), measured from these observations.
The primary way for measuring these galaxy properties is by analyzing their
spectral energy distribution (SED).

% primer on SED modeling 
All of the physical processes in a galaxy leave an imprint on its SED:
\emph{e.g.} its star formation history, chemical enrichment history, dust
content. 
For instance, the SED over the ultraviolet to infrared wavelengths is
primarily composed of light from the galaxy's stellar populations. 
Some of this stellar light is reprocessed by the gas and dust in its
interstellar medium.
The goal of SED modeling is to extract these detailed physical properties of
galaxies that are encoded in observed SEDs. 
SED modeling involves three key components: the observations, a physical SED
model, and a statistical inference framework for deriving physical properties 
from the comparisons between the observations and SED models.

% brief primer on SPS 
Current SED models are based on stellar population synthesis (SPS).
Broadly speaking, they model the SED of a galaxy as a compsite stellar
population constructed based on isocrhones, stellar spectra, an initial mass
function (IMF), a star formation and chemical evolution history, and dust
attenuation~\citep[\emph{e.g.}][]{bruzual2003, maraston2005, conroy2009,
eldridge2017}.
Some models also include dust and nebular emissions as well as emissions from
active galactic nuclei (AGN)~\citep[\emph{e.g.}][]{johnson2021}.
For a comprehensive review on SPS and SED modeling, we refer readers to
\cite{walcher2011} and \cite{conroy2013}. 

% parameter inference for SED modeling
In this work, we focus on the third component of SED modeling: the statistical
framework for comparing SED models to observations and inferring galaxy
properties. 
State-of-the-art SED modeling use a Bayesian parameter inference framework.
This approach has a number of key advantages over maximum-likelihood 
approaches~\citep[\emph{e.g.}][]{cidfernandes2005, tojeiro2007, koleva2008} 
that were often used in the past.
In Bayesian inference, the goal is to estimate $p(\theta\given\bfi{x})$, the
probability distribution of parameters $\theta$, in our case galaxy
properties, given observation $\bfi{x}$. 
Inferring $p(\theta\given\bfi{x})$ provides an accurate estimate of parameter 
uncertainties and any degerancies among them.
These uncertainties can then be propagated to for more accurate statistical
analyses. 
The Bayesian framework also enables marginalization over nuisance parameters,
which are necessary to model the effects of observational systematics
(\emph{e.g.} flux calibration).
In principle, informative priors based on previous observations can also be
exploited in Bayesian inference to derive more precise constraints on galaxy
properties 

In practice, current methods use Markov Chain Monte Carlo (MCMC) based sampling
techniques to explore and estimate the
posterior~\citep{acquaviva2011, chevallard2016, carnall2017, leja2017}. 
MCMC sampling enables more accurate posterior estimation and addresses the
curse of dimensionality that restricts grid-based techniques used in the
past~\citep{kauffmann2003a, burgarella2005, salim2007, dacunha2008}.
Grid-based techniques require SED models to be pre-computed over a grid in
parameter space.
Hence, as the dimensionality of parameter space increases for more
sophisticated models, these techniques require exponentially large number of
model evaluations. 
For MCMC, the number of evaluations scales roughly linearly with the number of
parameters so they can be used to efficiently sample high dimensional parameter
spaces. 
The \cite{johnson2021} SED modeling, for instance, uses MCMC to sample a
16-dimensional parameter space. 

Despite these advantages, current Bayesian SED modeling methods are \emph{not
scalable} as upcoming galaxy surveys will observe an unprecedented number of
galaxies.
The Dark Energy Spectroscopic Survey~\citep[DESI;][]{desicollaboration2016},
the Prime Focus Spectrograph~\citep[PFS;][]{takada2014},
Rubin observatory~\citep{ivezic2019}, and Roman Space
Telescope~\citep{spergel2015} will all observe \emph{millions} of galaxy SEDs. 
Meanwhile, current SED modeling takes 10-100 CPU hours per
galaxy~\citep[\emph{e.g.}][]{carnall2019, tacchella2021}.
With current methods, inferring galaxy properties from rigorous Bayesian SED
modeling for upcoming surveys  would require \emph{billions} of CPU hours. 
%For example, in \cite{}, analyzing just ${\sim}4000$ galaxies in the LEGA-C ESO Public Spectroscopic Survey~\cite{} using {\sc Bagpipes} required 3.5 million CPU hours.

The computational challenge is further exacerbated by additional factors. 
First, more accurate and sophisticated SED models require additional
parameters. 
For instance, modeling any additional physical processes (\emph{e.g.} nebular
emission) requires additional parameters. 
More accurate modeling of observational effects also requires additional
parameters. 
As the parameter space expands, conventional sampling techniques become less
efficient. 
Second, it has recently come to light that the prior, used to evaluate the
posterior, can significantly impact the inferred galaxy
properties~\citep{carnall2017, leja2017, hahn2022}. 
This is a consequence of the fact that galaxy properties are not directly SED
model parameters but rather derived properties.
Hence, deriving robust galaxy properties requires validating the properties
using multiple different priors. 
For MCMC-based SED modeling, posteriors would need to be entirely re-evaluated
for each prior.
Lastly, current SED modeling make explicit choices for its stellar spectral
library and initial mass function, even though there is no consensus. 
Incorporating the uncertainties and variations in these choices would either
require including them in the SED model or exploring multiple different choices.
Both dramatically increases the computational costs of current SED modeling.  

Rigorous Bayesian inference does not require MCMC sampling of high-dimensional
posteriors. 
Simulation-based inference (SBI; also known as ``likelihood-free inference'')
is a rapidly developing class of inference methods that offers better
alternatives for many applications~\citep[see][and reference
therein]{cranmer2020}.
Many SBI methods leverage the latest developments in statistics and Machine
Learning for more efficient posterior estimation~\citep{papamakarios2017,
alsing2019a, hahn2019c, dax2021, huppenkothen2021, zhang2021}. 
One such SBI technique optimal for scalable Bayesian inference is Amortized
Neural Posterior Estimation (ANPE). 

ANPE utilizes a density estimation approach to SBI. 
Instead of MCMC sampling the posterior, $p(\theta \given \bf{x}_i)$, of a
single galaxy, $i$, ANPE uses neural density estimators (NDE) and training data
to estimate the $p(\theta\given\bf{x})$ distribution over the full space of
observables ${\bf x}$.
NDEs are density models parameterized by neural networks that estimate a
density/probability distributions. 
The training data are precomputed $\{(\theta_i, \bf{x}'_i\}$ pairs.
For our application, $\theta$ is the SED model parameters, sampled from a 
prior, and $\bf{x}'_i$ are mock observables, such as photometry, constructed
from the SED model run on $\theta_i$. 
Once the NDE is trained using this data, generating the posterior for a galaxy
only requires plugging in the observation $\bf{x}_i$ --- this takes ${\sim}1$
second. 

ANPE addresses one of the major drawbacks of MCMC: SED model evaluations used
for one galaxy cannot be used for another.
This is why MCMC sampling has to be repeated for every galaxy. 
In ANPE, models evaluations are only used to construct the training data of the
NDE. 
Although the training set typically requires more evaluations than for a single
MCMC posterior, no additional evaluations are necessary after training. 
Hence, the computational cost is \emph{amoritzed} and only a minuscule
fraction of the cost of performing MCMC to analyze a large set of observations.
ANPE has recently been applied to a wide range of applications in physics and
astronomy with remarkable success~\citep{stein2020, wong2020, dax2021,
zhang2021}.

In this work, we apply SBI using ANPE to Bayesian galaxy SED modeling. 
We demonstrate that with ANPE, we can make Bayesian SED modeling fully scalable
for the millions of galaxies that will be observed by upcoming surveys.
Furthermore, as further demonstration, we apply ANPE to analyze optical
photometry of ${\sim}33,000$ galaxies in the NASA-Sloan
Atlas~(NSA; \url{http://www.nsatlas.org/}). 
We begin in Section~\ref{sec:sbi} by describing SBI method using ANPE.
We describe the NSA observations in Section~\ref{sec:obs}. 
Then, we present {\sc SEDflow}, our SED modeling using ANPE, in
Section~\ref{sec:sedflow}. 
We validate the accuracy of the posteriors from {\sc SEDflow} in
Section~\ref{sec:results} and discuss the impliciation of our results and
future steps in Section~\ref{sec:discuss}. 
Finally, we summarize and conclude in Section~\ref{sec:summary}. 
