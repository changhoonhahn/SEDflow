\section{Discussion} \label{sec:discuss}
\subsection{Forward Model} \label{sec:forward-model}
In the previous section, we demonstrated the accuracy of \sedflow~posteriors. 
Nevertheless, a primary determining factor the fidelity of \sedflow, or any ML model, is
the quality of the training data set and, thus, the forward model used to
construct it. 
Below, we discuss the caveats and limitations of our forward model, which has
two components: the PROVABGS SED model and a noise model
(Section~\ref{sec:training}).

First, for our noise model, we assign noiseless photometric fluxes
uncertainties based on an empirical estimate of $p(\sigma_X\given f_X)$ for
each band independently. 
Afterwards, the assigned $\sigma_X$ is used to apply Gaussian noise to the
photometric flux (Eq.~\ref{eq:noise}). 
This is a simplicistic noise model and, as the bottom right ($g - \sigma_r$ and
$r - \sigma_r$) panels of Figure~\ref{fig:data} reveal, there are discrepancies
in the magnitude versus uncertainty distributions of the training data and
observations. 
Despite these discrepancies, \sedflow~provides excellent estimates of the true
posterior.  
This is because we design our ANPE to include $\sigma_X$ as a conditional
variable (Section~\ref{sec:anpe_train}).
The $f_X-\sigma_X$ distribution of our training data does not impact the
accuracy of the posteriors as long as there are sufficient training data near
$\bfi{x}$ to train the NDE in that region.

A more accurate noise model will, in theory, improve the performance of
\sedflow~because the $\bfi{x}$-space of the training data will more effectively
span the observations. 
In other words, there will be fewer training data expended in regions of 
$\bfi{x}$-space that are devoid of observations.  
However, for our application to SED modeling, we do not find significantly  
improved performance when we alter the noise model.
This suggests that even with our simplistic noise model, the
$\bfi{x}$-space of observations is covered sufficiently well by the training data. 
We note that when we decrease $N_{\rm train}$ to below 500,000,
\sedflow~posteriors are significantly less accurate. 
A more realistic forward model may reduce this $N_{\rm train}$ threshold for
accurate posteriors. 
However, generating $N_{\rm train} \sim 1,000,000$ training has a negligible
computational cost compared to MCMC SED modeling, so we do not consider it 
necessary to explore this further. 

Next, we consider limitations in the PROVABGS SED model used in our forward
model. 
Our SED model uses a compact and flexible prescription for SFH and ZH that can
describe a broad range of SFHs and ZHs.
However, the prescription is derived from simulated Illustris galaxies, whose
SFHs and ZHs may be not reflect the full range of SFHs and ZHs of real
galaxies.
If certain subpopulations of observed galaxies have SFHs and ZHs that cannot be
described by the PROVABGS prescriptions, they cannot be accurately
modeled. 
Furthermore, even if the PROVABGS SFH and ZH prescriptions are sufficient,
there are limitations in our understanding of stellar evolution. 

There is currently no consensus in the stellar evolution, stellar spectral
libraries, or IMF of galaxies~\citep[\emph{e.g.}][]{treu2010, vandokkum2010,
rosani2018, ge2019, sonnenfeld2019}.
The PROVABGS model uses MIST isochrones, \cite{chabrier2003} IMF, and the MILES
+ BaSeL spectral libraries. 
These choices limit the range of SEDs that can be produced by the training data. 
For instance, if galaxies have significant variations in their IMF, assuming a
fixed IMF would falsely limit the range of our training data.  
A more flexible SED model that includes uncertainties in SPS would broaden the
range of galaxy SEDs that can be modeled.
Data-driven approaches may also enable SED models to be more
descriptive~\citep[\emph{e.g.}][]{hogg2016, portillo2020}. 
Improving  SED models, however, is beyond the scope of this work. 
Our focus is on improving the Bayesian inference framework.
In that regard, the limitations of the SED model equally impacts conventional
approaches with MCMC. 

We encounter the caveats above when we apply \sedflow~to the NSA catalog. 
For a small fraction of NSA galaxy SEDs (591 out of 33,883), \sedflow~generates
posteriors that are outside of the prior volume. 
We encounter these failures because the photometry or photometric uncertainties
of these galaxies lie outside of the support of the training data where
\sedflow~is not trained. 
They either have higher photometric uncertainties, for a given magnitude, or
bluer photometric colors than the training data. 
Some of these may be observational artifacts or problematic photometry.
Nevertheless, \sedflow~fails because the limitations in our noise and SPS
models, mentioned above, prevent us from construct training data near them. 
Since this issue only affects a small fraction of the NSA galaxies, we flag
them in our catalog and infer their galaxy properties by applying PROVABGS with
MCMC sampling for completeness.
For more details on these failures, we refer readers to
Appendix~\ref{sec:fail}.

To test for limitations of the forward model, we can construct additional tests
of posteriors derived from ANPE. 
For instance, the $\chi^2$ of the best-fit parameter value from the 
estimated posterior can be used to assess whether the best-fit model 
accurately reproduces observations.
This would only require one additional model evaluation per galaxy. 
As another test of the posteriors, one can construct an Amortized Neural
Likelihood Estimator (ANLE) using the same training data.
Unlike the ANPE, which estimates $p(\btheta\given f_X, \sigma_X, z)$, the ANLE
would estimate $p(f_X \given \btheta, \sigma_X, z)$.
We can then further validate the posteriors by assessing whether the observed
photometry lies within the ANLE. 
Based on the overall high level of accuracy of \sedflow~posteriors, we do not
explore these additional tests; however, they can be used to further validate
any ANPE posterior. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Advantages of \sedflow} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The primary advantage of \sedflow~is its computational speed. 
This becomes even more relevant if one wants to add further parameters to
address the concerns about the choices in current SPS models we described 
in Section~\ref{sec:forward-model}.
To relax these assumptions, SPS models would need to introduce additional
parameters that flexibly model these uncertainties~\citep{conroy2009,
conroy2010c}. 
While the dimensionality of current SPS models already makes MCMC methods
computational infeasible, ANPE has already been applied to higher dimensional
applications.
For instance, \cite{dax2021} constructed an accurate ANPE for a
15-dimensional model parameter space and 128-dimensional conditional variable
space.
NDE is an actively developing field in ML and new methods are constantly
emerging~\citep[\eg][]{wu2020, dhariwal2021}. 
Since ANPE can handle higher dimensionality, we can in the future include additional
parameters that model uncertainties in SPS. 
This will not only improve our SED modeling, but also improve our understanding
of stellar evolution and the IMF.

In addition to enabling scalable SED modeling for the next generation galaxy
surveys, \sedflow~will enable us to tackle other key challenges in SED
modeling. 
For example, recent works have demonstrated that priors of SED models can
significantly impact the inferred galaxy properties~\citep{carnall2018,
leja2019, hahn2022}. 
Even ``uniformative'' uniform priors on SED model parameters can impose
undesirable priors on derived galaxy properties such as $M_*$, SFR, SFH, or
ZH.
To avoid significant biases, galaxy studies must carefully select priors and
validate their results using multiple different choices. 
With an MCMC approach, selecting a different prior means reevaluating every
posterior and repeating all the SED model evaluations in the MCMC sampling.  

%\sedflow~requires substantially fewer model evaluations overall; however, the
%advantages extend even further. 
For an ANPE approach, the prior is set by the distribution of parameters in the
training data. 
For a new prior, instead of reconstructing the training data, we can resample
it in such a way that the parameters follow the new prior.
Then, the ANPE model can be re-trained, re-validated on the test data, and
re-deployed on observations.
Each of these steps require substantially less computational resources than
generating a new set of training data or using MCMC methods. 
Hence, the ANPE approach provides a way to efficiently vary the prior without
multiplying computational costs.


%First, more accurate and sophisticated SED models require additional
%parameters, for instance, to model nebular emission of observational
%systematics. 
%Lastly, current SPS models make strong theoretical assuptions. 
%They make explicit choices for stellar spectral library and initial mass
%function, but there is currently no consensus on the best choices for either.
%Relaxing these assumptions would involve parameterizing the uncertainties and
%variations as additional parameters in SED models~\citep{conroy2009,
%conroy2010c} or deriving galaxy properties for multiple sets of assumptions. 
%Both options increase the computational costs of current SED modeling.  
